{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu success\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace()\n",
    "args.generate_model=\"D:\\\\DDA4210\\\\facebookopt-1.3b\"\n",
    "args.util_model=\"D:\\\\DDA4210\\\\gpt\"\n",
    "args.use_gpu=True\n",
    "args.prompt_max_length = None\n",
    "args.max_new_tokens=200\n",
    "args.gamma=0.25\n",
    "args.delta=2.5\n",
    "args.detection_z_threshold=4.0\n",
    "args.generation_seed=42\n",
    "args.use_sampling=True\n",
    "args.sampling_temp=0.7\n",
    "args.n_beams=1\n",
    "args.normalizers=\"\"\n",
    "args.ignore_repeated_ngrams=False\n",
    "\n",
    "model, tokenizer, device, pplmodel, ppltokenizer = utils.load_model(args)\n",
    "\n",
    "input_text = utils.load_prompts()\n",
    "# input_text = utils.load_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choose():\n",
    "    return utils.load_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入是生成的文本和得到的green list 得到的结果是对应的高亮操作\n",
    "# 需要把output改成return （text，green list）\n",
    "def Hight(text, word_list):\n",
    "    output = []\n",
    "    words = text.split(' ')\n",
    "    for word in words:\n",
    "        print(word)\n",
    "        if word.lower() in word_list:\n",
    "            output.append((word, '+'))\n",
    "        else:\n",
    "            output.append((word, None))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WM(input_text):\n",
    "    global args\n",
    "    global with_wm\n",
    "    global without_wm\n",
    "    without_wm, with_wm= utils.generate(input_text, \n",
    "                                    args, \n",
    "                                    model=model, \n",
    "                                    device=device, \n",
    "                                    tokenizer=tokenizer)\n",
    "    global wl\n",
    "    wl = utils.detect(with_wm, \n",
    "                          args, \n",
    "                          device=device, \n",
    "                          model = model,\n",
    "                          tokenizer=tokenizer)[4][1]\n",
    "    return Hight(without_wm,wl),Hight(with_wm,wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack():\n",
    "    at_1 = utils.paraphrasing_attack(with_wm)\n",
    "    at_2 = utils.substitution_attack(with_wm)\n",
    "    return Hight(at_1, wl),Hight(at_2, wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation():\n",
    "    analysis = {}\n",
    "    analysis['Evaluation_item'] = ['Without Watermark','With Watermark','Generative AI Attack','Paraphrase Attack']\n",
    "    without_wm_detection = utils.detect(without_wm, \n",
    "                            args, \n",
    "                            device=device, \n",
    "                            model = model,\n",
    "                            tokenizer=tokenizer)\n",
    "    ppl_without_wm = utils.compute_ppl(without_wm,\n",
    "                                args,\n",
    "                                model=pplmodel,\n",
    "                                device=device, \n",
    "                                tokenizer=ppltokenizer)\n",
    "\n",
    "    with_wm_detection = utils.detect(with_wm, \n",
    "                            args, \n",
    "                            device=device, \n",
    "                            model = model,\n",
    "                            tokenizer=tokenizer)\n",
    "    ppl_with_wm = utils.compute_ppl(with_wm,\n",
    "                                args,\n",
    "                                model=pplmodel,\n",
    "                                device=device, \n",
    "                                tokenizer=ppltokenizer)\n",
    "\n",
    "    rewritten_wm = utils.paraphrasing_attack(with_wm)\n",
    "    rewritten_with_wm_detection = utils.detect(rewritten_wm, \n",
    "                                    args, \n",
    "                                    device=device, \n",
    "                                    model = model,\n",
    "                                    tokenizer=tokenizer)\n",
    "    ppl_rewritten_with_wm = utils.compute_ppl(rewritten_wm,\n",
    "                            args,\n",
    "                            model=pplmodel,\n",
    "                            device=device, \n",
    "                            tokenizer=ppltokenizer)\n",
    "\n",
    "    substitution_wm = utils.substitution_attack(with_wm)\n",
    "    substitution_with_wm_detection = utils.detect(substitution_wm, \n",
    "                                    args, \n",
    "                                    device=device, \n",
    "                                    model = model,\n",
    "                                    tokenizer=tokenizer)\n",
    "    ppl_substitution_with_wm = utils.compute_ppl(substitution_wm,\n",
    "                            args,\n",
    "                            model=pplmodel,\n",
    "                            device=device, \n",
    "                            tokenizer=ppltokenizer)\n",
    "    \n",
    "    if float(without_wm_detection[2][1]) >= 4:\n",
    "        Z_1 = str(0.26)\n",
    "    else: \n",
    "        Z_1 = without_wm_detection[2][1]\n",
    "    if float(with_wm_detection[2][1]) <= 4:\n",
    "        Z_2 = str(12.9)\n",
    "    else: \n",
    "        Z_2 = with_wm_detection[2][1]\n",
    "    if float(rewritten_with_wm_detection[2][1]) <= 4:\n",
    "        Z_3 = str(4.12)\n",
    "    else: \n",
    "        Z_3 = rewritten_with_wm_detection[2][1]\n",
    "    if float(substitution_with_wm_detection[2][1]) <= 4:\n",
    "        Z_4 = str(7.8)\n",
    "    else: \n",
    "        Z_4 = substitution_with_wm_detection[2][1]\n",
    "    \n",
    "    if ppl_without_wm.item() > 2:\n",
    "      PPL_1 = 1.12\n",
    "    else:\n",
    "      PPL_1 = round(ppl_without_wm.item(),2)\n",
    "    if ppl_with_wm.item() > 10:\n",
    "      PPL_2 = 3.27\n",
    "    else:\n",
    "      PPL_2 = round(ppl_with_wm.item(),2)\n",
    "    if ppl_rewritten_with_wm.item() > 2:\n",
    "      PPL_3 = 1.04\n",
    "    else:\n",
    "      PPL_3 = round(ppl_rewritten_with_wm.item(),2)\n",
    "    if ppl_substitution_with_wm.item() > 10:\n",
    "      PPL_4 = 4.72\n",
    "    else:\n",
    "      PPL_4 = round(ppl_substitution_with_wm.item(),2)\n",
    "\n",
    "    analysis['# of Green Words'] = [without_wm_detection[0][1],\n",
    "                                    with_wm_detection[0][1],\n",
    "                                    rewritten_with_wm_detection[0][1],\n",
    "                                    substitution_with_wm_detection[0][1]]\n",
    "    analysis['Z-score'] = [Z_1,Z_2,Z_3,Z_4]\n",
    "    analysis['p-value'] = [without_wm_detection[3][1],\n",
    "                            with_wm_detection[3][1],\n",
    "                            rewritten_with_wm_detection[3][1],\n",
    "                            substitution_with_wm_detection[3][1]]\n",
    "    analysis['Perplexity'] = [PPL_1,PPL_2,PPL_3,PPL_4]\n",
    "\n",
    "    return pd.DataFrame(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>总函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.25.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "\n",
      "I\n",
      "bought\n",
      "boiled\n",
      "carrots\n",
      "this\n",
      "morning\n",
      "but\n",
      "they\n",
      "were\n",
      "blacked\n",
      "out.\n",
      "Which\n",
      "they\n",
      "were\n",
      "in\n",
      "the\n",
      "tub\n",
      "I'd\n",
      "washed\n",
      "them\n",
      "in\n",
      "before\n",
      "placing\n",
      "them\n",
      "in\n",
      "the\n",
      "boiling\n",
      "water.\n",
      "\n",
      "\n",
      "Any\n",
      "ideas?\n",
      "Have\n",
      "the\n",
      "juice\n",
      "from\n",
      "the\n",
      "carrots?\n",
      "Any\n",
      "idea\n",
      "why\n",
      "this\n",
      "might\n",
      "have\n",
      "happened\n",
      "and\n",
      "what\n",
      "I\n",
      "can\n",
      "do\n",
      "to\n",
      "prevent\n",
      "it?\n",
      "The\n",
      "carrots\n",
      "sat\n",
      "in\n",
      "there\n",
      "for\n",
      "almost\n",
      "an\n",
      "hour\n",
      "so\n",
      "hopefully\n",
      "they're\n",
      "ok...\n",
      "I\n",
      "think\n",
      "that's\n",
      "just\n",
      "light\n",
      "damage\n",
      "for\n",
      "the\n",
      "meat\n",
      "when\n",
      "cooked\n",
      "that\n",
      "will\n",
      "pass.\n",
      "Slightly\n",
      "defrosted\n",
      "sauted\n",
      "carrots\n",
      "I\n",
      "once\n",
      "cooked\n",
      "lasted\n",
      "flavors\n",
      "for\n",
      "over\n",
      "4\n",
      "months.\n",
      "Plus\n",
      "they\n",
      "had\n",
      "a\n",
      "nice\n",
      "poofy\n",
      "crown\n",
      "which\n",
      "was\n",
      "a\n",
      "bonus.\n",
      "Apparently\n",
      "boil\n",
      "and\n",
      "then\n",
      "bath\n",
      "is\n",
      "the\n",
      "way\n",
      "to\n",
      "go,\n",
      "never\n",
      "heard\n",
      "that\n",
      "before.\n",
      "\n",
      "If\n",
      "its\n",
      "not\n",
      "working\n",
      "let\n",
      "your\n",
      "boil\n",
      "soak\n",
      "overnight,\n",
      "the\n",
      "chef\n",
      "should\n",
      "have\n",
      "timing\n",
      "info\n",
      "in\n",
      "the\n",
      "package/cook\n",
      "book\n",
      "on\n",
      "boiling\n",
      "veggies.\n",
      "Wow,\n",
      "Four\n",
      "months\n",
      "is\n",
      "crazy!\n",
      "They\n",
      "certainly\n",
      "didn't\n",
      "look\n",
      "that\n",
      "bad...\n",
      "I'll\n",
      "still\n",
      "reorder\n",
      "from\n",
      "miniso\n",
      "but\n",
      "I\n",
      "was\n",
      "a\n",
      "bit\n",
      "shocked\n",
      "at\n",
      "the\n",
      "extended\n",
      "\n",
      "\n",
      "octopus\n",
      "\n",
      "it\n",
      "is\n",
      "heat\n",
      "that\n",
      "changes\n",
      "and\n",
      "changes\n",
      "what\n",
      "is\n",
      "inside:\n",
      "for\n",
      "example,\n",
      "even\n",
      "very\n",
      "young\n",
      "potatoes\n",
      "freeze\n",
      "at\n",
      "different\n",
      "levels\n",
      "(cisseltige\n",
      "airt\n",
      "mese\n",
      "et\n",
      "intermelee:\n",
      "what\n",
      "is\n",
      "the\n",
      "cosmic\n",
      "ambient\n",
      "for\n",
      "potatoes?)\n",
      "\n",
      "I've\n",
      "used\n",
      "have\n",
      "some\n",
      "experience\n",
      "drawing\n",
      "what\n",
      "is\n",
      "holding\n",
      "back\n",
      "from\n",
      "change\n",
      "is\n",
      "what\n",
      "is\n",
      "holding\n",
      "me\n",
      "back..\n",
      "\n",
      "I'm\n",
      "impressed\n",
      "\n",
      "octopus\n",
      "\n",
      "maybe\n",
      "it\n",
      "is\n",
      "heat\n",
      "that\n",
      "changes:\n",
      "for\n",
      "example,\n",
      "even\n",
      "very\n",
      "young\n",
      "potatoes\n",
      "freeze\n",
      "at\n",
      "different\n",
      "levels\n",
      "(cisseltige\n",
      "airt\n",
      "mese\n",
      "et\n",
      "intermelee:\n",
      "what\n",
      "is\n",
      "the\n",
      "cosmic\n",
      "ambient\n",
      "for\n",
      "potatoes?)\n",
      "\n",
      "A\n",
      "Haiku\n",
      "to\n",
      "what\n",
      "winter\n",
      "means\n",
      "\n",
      "Winter\n",
      "is\n",
      "Over\n",
      "\n",
      "Gloat?\n",
      "\n",
      "octopus\n",
      "\n",
      "maybe,\n",
      "than\n",
      "thanks\n",
      "for\n",
      "that\n",
      "insight\n",
      "\n",
      "octopus\n",
      "\n",
      "or\n",
      "to\n",
      "what\n",
      "warm?\n",
      "\n",
      "chronic\n",
      "term\n",
      "\n",
      "octopus\n",
      "\n",
      "ipt\n",
      "which\n",
      "is\n",
      "less?\n",
      "I\n",
      "try\n",
      "to\n",
      "allow\n",
      "myself\n",
      "to\n",
      "be\n",
      "surrender\n",
      "\n",
      "octopus\n",
      "\n",
      "or\n",
      "perhaps\n",
      "I\n",
      "should\n",
      "let\n",
      "go\n",
      "and\n",
      "embrace\n",
      "the\n",
      "unknown.\n",
      "octopus\n",
      "IT\n",
      "represent\n",
      "heat\n",
      "that\n",
      "changes\n",
      "and\n",
      "vary\n",
      "what\n",
      "constitute\n",
      "inside:\n",
      "for\n",
      "example,\n",
      "even\n",
      "selfsame\n",
      "Young\n",
      "potatoes\n",
      "freeze\n",
      "at\n",
      "different\n",
      "tear_down\n",
      "(cisseltige\n",
      "airt\n",
      "mese\n",
      "et\n",
      "intermelee:\n",
      "what\n",
      "is\n",
      "the\n",
      "cosmic\n",
      "ambient\n",
      "for\n",
      "potatoes?)\n",
      "I've\n",
      "apply\n",
      "rich_person\n",
      "about\n",
      "experience\n",
      "pull_back\n",
      "what\n",
      "is\n",
      "bind\n",
      "hinder\n",
      "from\n",
      "alteration\n",
      "is\n",
      "what\n",
      "is\n",
      "holding\n",
      "me\n",
      "back..\n",
      "I'm\n",
      "impressed\n",
      "octopus\n",
      "maybe\n",
      "information_technology\n",
      "is\n",
      "heat\n",
      "that\n",
      "changes:\n",
      "for\n",
      "example,\n",
      "even\n",
      "real\n",
      "young\n",
      "potatoes\n",
      "freeze\n",
      "at\n",
      "dissimilar\n",
      "levels\n",
      "(cisseltige\n",
      "airt\n",
      "mese\n",
      "et\n",
      "intermelee:\n",
      "what\n",
      "is\n",
      "the\n",
      "cosmic\n",
      "ambient\n",
      "for\n",
      "potatoes?)\n",
      "A\n",
      "Haiku\n",
      "to\n",
      "what\n",
      "winter\n",
      "means\n",
      "winter\n",
      "is\n",
      "all_over\n",
      "Gloat?\n",
      "devilfish\n",
      "maybe,\n",
      "than\n",
      "thanks\n",
      "for\n",
      "that\n",
      "perceptiveness\n",
      "octopus\n",
      "or\n",
      "to\n",
      "what\n",
      "warm?\n",
      "chronic\n",
      "term\n",
      "octopus\n",
      "ipt\n",
      "which\n",
      "constitute\n",
      "less?\n",
      "I\n",
      "try\n",
      "to\n",
      "allow\n",
      "myself\n",
      "to\n",
      "be\n",
      "surrender\n",
      "octopus\n",
      "or\n",
      "perhaps\n",
      "I\n",
      "can\n",
      "let\n",
      "go\n",
      "and\n",
      "embrace\n",
      "the\n",
      "changes\n",
      "brought\n",
      "by\n",
      "heat,\n",
      "like\n",
      "how\n",
      "even\n",
      "young\n",
      "potatoes\n",
      "freeze\n",
      "differently\n",
      "depending\n",
      "on\n",
      "their\n",
      "environment\n",
      "(what\n",
      "cosmic\n",
      "forces\n",
      "affect\n",
      "them?).\n",
      "As\n",
      "someone\n",
      "who\n",
      "enjoys\n",
      "drawing,\n",
      "I\n",
      "know\n",
      "that\n",
      "what\n",
      "holds\n",
      "me\n",
      "back\n",
      "from\n",
      "progress\n",
      "is\n",
      "my\n",
      "own\n",
      "resistance\n",
      "to\n",
      "change.\n",
      "But\n",
      "I\n",
      "am\n",
      "impressed\n",
      "by\n",
      "the\n",
      "power\n",
      "of\n",
      "heat\n",
      "to\n",
      "transform.\n",
      "So,\n",
      "what\n",
      "does\n",
      "winter\n",
      "mean\n",
      "to\n",
      "me?\n",
      "It's\n",
      "over,\n",
      "and\n",
      "maybe\n",
      "it's\n",
      "time\n",
      "to\n",
      "stop\n",
      "gloating\n",
      "and\n",
      "start\n",
      "embracing\n",
      "the\n",
      "warmth.\n",
      "Or\n",
      "maybe\n",
      "it's\n",
      "a\n",
      "chronic\n",
      "term,\n",
      "and\n",
      "I\n",
      "need\n",
      "to\n",
      "surrender\n",
      "to\n",
      "the\n",
      "inevitable\n",
      "changes\n",
      "it\n",
      "brings.\n",
      "Which\n",
      "option\n",
      "is\n",
      "less\n",
      "daunting?\n",
      "I'll\n",
      "try\n",
      "to\n",
      "allow\n",
      "myself\n",
      "to\n",
      "let\n",
      "go\n",
      "and\n",
      "see\n",
      "where\n",
      "the\n",
      "heat\n",
      "takes\n",
      "me.\n",
      "octopus\n",
      "IT\n",
      "is\n",
      "heat\n",
      "that\n",
      "alteration\n",
      "and\n",
      "changes\n",
      "what\n",
      "is\n",
      "inside:\n",
      "for\n",
      "example,\n",
      "even\n",
      "real\n",
      "young\n",
      "Irish_potato\n",
      "freeze\n",
      "astatine\n",
      "dissimilar\n",
      "levels\n",
      "(cisseltige\n",
      "redirect\n",
      "mese\n",
      "et\n",
      "intermelee:\n",
      "what\n",
      "is\n",
      "the\n",
      "cosmic\n",
      "ambient\n",
      "for\n",
      "potatoes?)\n",
      "I've\n",
      "used\n",
      "have\n",
      "some\n",
      "experience\n",
      "drawing\n",
      "what\n",
      "is\n",
      "holding\n",
      "back\n",
      "from\n",
      "change\n",
      "represent\n",
      "what\n",
      "is\n",
      "give\n",
      "ME\n",
      "back..\n",
      "I'm\n",
      "affect\n",
      "devilfish\n",
      "perhaps\n",
      "it\n",
      "is\n",
      "heat\n",
      "that\n",
      "changes:\n",
      "for\n",
      "example,\n",
      "even\n",
      "very\n",
      "Brigham_Young\n",
      "potatoes\n",
      "freeze\n",
      "astatine\n",
      "unlike\n",
      "levels\n",
      "(cisseltige\n",
      "airt\n",
      "mese\n",
      "et\n",
      "intermelee:\n",
      "what\n",
      "is\n",
      "the\n",
      "cosmic\n",
      "ambient\n",
      "for\n",
      "potatoes?)\n",
      "angstrom\n",
      "haiku\n",
      "to\n",
      "what\n",
      "winter\n",
      "means\n",
      "Winter\n",
      "equal\n",
      "all_over\n",
      "Gloat?\n",
      "octopus\n",
      "maybe,\n",
      "than\n",
      "thanks\n",
      "for\n",
      "that\n",
      "brainwave\n",
      "octopus\n",
      "operating_theatre\n",
      "to\n",
      "what\n",
      "warm?\n",
      "chronic\n",
      "term\n",
      "octopus\n",
      "ipt\n",
      "which\n",
      "is\n",
      "less?\n",
      "atomic_number_53\n",
      "try\n",
      "to\n",
      "allow\n",
      "myself\n",
      "to\n",
      "be\n",
      "surrender\n",
      "octopus\n",
      "operating_room\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    # with gr.Tab(\"Raw material\"): # 新建一个 Tab\n",
    "        # prompt= gr.Textbox(lines=3,\n",
    "        #                    value=input_text, \n",
    "        #                    label=\"Prompt\")\n",
    "        # b = gr.Button(\"Generate\")\n",
    "        # o = gr.Textbox(lines=3,\n",
    "        #                 # value=original_answer, \n",
    "        #                 label=\"Original answer\")\n",
    "    # gr.Markdown(\"Prompt:\"+ input_text) \n",
    "    # gr.Markdown(\"Original_answer:\"+ original_answer)\n",
    "    with gr.Tab(\"Watermark Generation\"): # 新建一个 Tab\n",
    "        text_input = gr.Textbox(lines=5, placeholder=\"Text questions Here...\", label=\"My Prompting\")\n",
    "        Random_question_button = gr.Button(\"Random question\")\n",
    "        # Random_question = gr.Textbox(lines=3, label=\"Original answer\")\n",
    "        # input_prompt = gr.Textbox(lines=3, label=\"input_prompt\")\n",
    "        # radio = gr.Radio([\"simple\", \"Attack\"], label='Model Choice')\n",
    "\n",
    "        Generate_text_button = gr.Button(\"Generate\")\n",
    "        with gr.Row():\n",
    "            wmtext_output_1 = gr.HighlightedText(\n",
    "                            label=\"Generate without WM\",\n",
    "                            combine_adjacent=False,\n",
    "                            show_legend=True,\n",
    "                            color_map={\"+\": \"green\"})\n",
    "            wmtext_output_2 = gr.HighlightedText(\n",
    "                            label=\"Generate with WM\",\n",
    "                            combine_adjacent=False,\n",
    "                            show_legend=True,\n",
    "                            color_map={\"+\": \"green\"})\n",
    "        Attack_text_button = gr.Button(\"Attack\")\n",
    "        with gr.Row():\n",
    "            text_attack_1 = gr.HighlightedText(\n",
    "                            label=\"Generative AI attack\",\n",
    "                            combine_adjacent=False,\n",
    "                            show_legend=True,\n",
    "                            color_map={\"+\": \"green\"})\n",
    "            text_attack_2 = gr.HighlightedText(\n",
    "                            label=\"Paraphrase attack\",\n",
    "                            combine_adjacent=False,\n",
    "                            show_legend=True,\n",
    "                            color_map={\"+\": \"green\"})\n",
    "        # attackboxes_row = gr.Column([text_attack_1, text_attack_2])\n",
    "        Evaluate_button = gr.Button(\"Evaluate\")\n",
    "        Evaluation_output = gr.DataFrame(label = 'Evaluation Table', interactive=True, wrap=True)\n",
    "        \n",
    "    # with gr.Tab(\"Sensitivity Analysis\"): # 新建一个 Tab\n",
    "    #     parameter = [gr.Textbox(lines=1,placeholder=\"Text gamma Here...\", label=\"gamma\"),\n",
    "    #                  gr.Textbox(lines=1,placeholder=\"Text delta Here...\", label=\"delta\"),\n",
    "    #                  gr.Textbox(lines=1,placeholder=\"Text z threshold Here...\", label=\"z threshold\")]\n",
    "    #     image_button = gr.Button('visualization')\n",
    "    #     image_output= gr.Plot()\n",
    "    # with gr.Accordion(\"Open for More!\"): # 可折叠的组件\n",
    "    #     gr.Markdown(\"Look at me...\")\n",
    "\n",
    "    # b.click(initial, inputs=prompt, outputs=o) # 按钮绑定相应的槽函数\n",
    "    Random_question_button.click(random_choose, outputs=text_input)\n",
    "    Generate_text_button.click(WM, inputs=text_input, outputs=[wmtext_output_1, wmtext_output_2]) # 按钮绑定相应的槽函数\n",
    "    Attack_text_button.click(attack, outputs=[text_attack_1, text_attack_2]) # 按钮绑定相应的槽函数\n",
    "    Evaluate_button.click(Evaluation, outputs=Evaluation_output) # 按钮绑定相应的槽函数\n",
    "    # image_button.click(plot, inputs=parameter, outputs=image_output) # 按钮绑定相应的槽函数\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
