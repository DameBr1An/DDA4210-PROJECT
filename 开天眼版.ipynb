{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6,font face = 'Times New Roman'>**Group Project**  \n",
    "<font size=4,font face = 'Times New Roman'>学号+姓名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5,font face = 'Times New Roman'>**Import library**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu success\n",
      "prompt: how does the eye-sight-measuring machine at the glasses shop actually give you the exact number of your eyesight?\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace()\n",
    "args.generate_model=\"D:\\\\DDA4210\\\\facebookopt-1.3b\"\n",
    "args.util_model=\"D:\\\\DDA4210\\\\gpt\"\n",
    "args.use_gpu=True\n",
    "args.prompt_max_length = None\n",
    "args.max_new_tokens=200\n",
    "args.gamma=0.25\n",
    "args.delta=2.0\n",
    "args.detection_z_threshold=4.0\n",
    "args.generation_seed=42\n",
    "args.use_sampling=True\n",
    "args.sampling_temp=0.7\n",
    "args.n_beams=1\n",
    "args.normalizers=\"\"\n",
    "args.ignore_repeated_ngrams=False\n",
    "\n",
    "model, tokenizer, device, pplmodel, ppltokenizer = utils.load_model(args)\n",
    "\n",
    "input_text = utils.load_prompts()\n",
    "# input_text = utils.load_prompts()\n",
    "print('prompt: ' + input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>第一个tap 用来简单prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choose():\n",
    "    return utils.load_prompts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>第二个tap 第一部分 生成文本并且hightlight green list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入是生成的文本和得到的green list 得到的结果是对应的高亮操作\n",
    "# 需要把output改成return （text，green list）\n",
    "def Hight(text, word_list):\n",
    "    output = []\n",
    "    words = text.split(' ')\n",
    "    print(words)\n",
    "    for word in words:\n",
    "        print(word)\n",
    "        if word.lower() in word_list:\n",
    "            output.append((word, '+'))\n",
    "        else:\n",
    "            output.append((word, None))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WM(input_text):\n",
    "    global args\n",
    "    global with_wm\n",
    "    without_wm, with_wm= utils.generate(input_text, \n",
    "                                    args, \n",
    "                                    model=model, \n",
    "                                    device=device, \n",
    "                                    tokenizer=tokenizer)\n",
    "    global wl\n",
    "    wl = utils.detect(with_wm, \n",
    "                          args, \n",
    "                          device=device, \n",
    "                          model = model,\n",
    "                          tokenizer=tokenizer)[4][1]\n",
    "    return Hight(without_wm,wl),Hight(with_wm,wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack():\n",
    "    at_1 = utils.paraphrasing_attack(with_wm)\n",
    "    at_2 = utils.substitution_attack(with_wm)\n",
    "    return Hight(at_1, wl),Hight(at_2, wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def WM(a,b):\n",
    "#     word_list = ['The', 'was', 'devised', 'Phil', 'as', 'attack', 'weak', \\\n",
    "#                  'side', 'The', 'consists', 'power', 'guard', 'The', 'power', \\\n",
    "#                 'primary', 'scorer', 'while', 'primary', 'rebound', 'The', \\\n",
    "#                 'guard', 'primary', 'play', 'while', 'power', 'primary', \\\n",
    "#                 'distributor', 'The', 'was', 'devised', 'Phil', 'as', \\\n",
    "#                 'attack', 'weak', 'side', 'The', 'consists', 'power', \\\n",
    "#                 'guard', 'The', 'power', 'primary', 'scorer', 'while',\\\n",
    "#                  'primary', 'rebound', 'The', 'guard', 'primary', 'play', \\\n",
    "#                 'while', 'power', 'primary', 'distributor', 'The', 'was', \\\n",
    "#                 'devised', 'Phil', 'as', 'attack', 'weak', 'side', 'The', \\\n",
    "#                 'consists', 'power', 'guard', 'The', 'power', 'primary', \\\n",
    "#                 'scorer', 'while', 'primary', 'rebound', 'The', 'guard', \\\n",
    "#                 'primary', 'play', 'while']\n",
    "#     str1 =\"\"\"The triangle offense was devised by Phil Jackson as a way to attack the weak side of the defense. \n",
    "#     The triangle consists of a power forward, a center, and a guard. \n",
    "#     The power forward is the primary scorer while the center is the main rebounder. \n",
    "#     The guard is the playmaker while the rebounder is the distributor.\n",
    "#     In order to execute the triangle offense, you need to be able to score from the weakside of the court. \n",
    "#     The primary scorer should be able score from both the weak and strong side of his position. \n",
    "#     The playmaker should be a playmaker that can create his own shot while the rebounding guard should be the primary rebounder while the power forward should be his primary scorer.\n",
    "#     The primary scorer needs to be a scorer that can score from either side of him while the playmakers needs to create his shot while rebounding. \n",
    "#     The rebounding power forward needs to rebound while the primary scorers needs to score while rebinding.\"\"\"\n",
    "#     str2 =\"\"\"must have good ball movement and communication between players to effectively run the triangle offense. \n",
    "#     The power forward, center, and guard must work together to create scoring opportunities and exploit the weaknesses of the defense. \n",
    "#     It is essential for players to understand their roles and responsibilities within the offense in order to be successful.\"\"\"\n",
    "#     if b == 'simple':\n",
    "#         return Hight(str1,word_list)\n",
    "#     if b == '\"Paraphrasing Attack\"':\n",
    "#         return Hight(str2,word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>第二个tap 第二部分 生成evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正常版\n",
    "def Evaluation(text,operation):\n",
    "    global args\n",
    "    analysis = {}\n",
    "    analysis['gamma'] = args.gamma\n",
    "    analysis['delta'] = args.delta\n",
    "    analysis['z_threshold'] = args.detection_z_threshold\n",
    "    without_wm, with_wm= utils.generate(text, \n",
    "                                        args, \n",
    "                                        model=model, \n",
    "                                        device=device, \n",
    "                                        tokenizer=tokenizer)\n",
    "    if operation == 'simple':\n",
    "        with_wm_detection = utils.detect(with_wm, \n",
    "                                args, \n",
    "                                device=device, \n",
    "                                model = model,\n",
    "                                tokenizer=tokenizer)\n",
    "        analysis['T'] = with_wm_detection[0][1]\n",
    "        analysis['z'] = with_wm_detection[2][1]\n",
    "        analysis['p'] = with_wm_detection[3][1]\n",
    "        analysis['prediction'] = with_wm_detection[6][1]\n",
    "        ppl_with_wm = utils.compute_ppl(with_wm,\n",
    "                                args,\n",
    "                                model=pplmodel,\n",
    "                                device=device, \n",
    "                                tokenizer=ppltokenizer)\n",
    "        analysis['ppl'] = ppl_with_wm\n",
    "    \n",
    "\n",
    "    if operation == \"Paraphrasing Attack\":\n",
    "        rewritten_wm = utils.paraphrasing_attack(with_wm)\n",
    "        rewritten_with_wm_detection = utils.detect(rewritten_wm, \n",
    "                                        args, \n",
    "                                        device=device, \n",
    "                                        model = model,\n",
    "                                        tokenizer=tokenizer)\n",
    "        analysis['T'] = rewritten_with_wm_detection[0][1]\n",
    "        analysis['z'] = rewritten_with_wm_detection[2][1]\n",
    "        analysis['p'] = rewritten_with_wm_detection[3][1]\n",
    "        analysis['prediction'] = rewritten_with_wm_detection[6][1]\n",
    "        ppl_rewritten_with_wm = utils.compute_ppl(rewritten_wm,\n",
    "                                args,\n",
    "                                model=pplmodel,\n",
    "                                device=device, \n",
    "                                tokenizer=ppltokenizer)\n",
    "        analysis['ppl'] = ppl_rewritten_with_wm\n",
    "\n",
    "    if operation == \"Paraphrasing Attack\":\n",
    "        rewritten_wm = utils.substitution_attack(with_wm)\n",
    "        rewritten_with_wm_detection = utils.detect(rewritten_wm, \n",
    "                                        args, \n",
    "                                        device=device, \n",
    "                                        model = model,\n",
    "                                        tokenizer=tokenizer)\n",
    "        analysis['T'] = rewritten_with_wm_detection[0][1]\n",
    "        analysis['z'] = rewritten_with_wm_detection[2][1]\n",
    "        analysis['p'] = rewritten_with_wm_detection[3][1]\n",
    "        analysis['prediction'] = rewritten_with_wm_detection[6][1]\n",
    "        ppl_rewritten_with_wm = utils.compute_ppl(rewritten_wm,\n",
    "                                args,\n",
    "                                model=pplmodel,\n",
    "                                device=device, \n",
    "                                tokenizer=ppltokenizer)\n",
    "        analysis['ppl'] = ppl_rewritten_with_wm\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(analysis)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开天眼版\n",
    "def table(analysis,operation):\n",
    "    data = {'gamma': [0.25], \n",
    "            'delta': [2.0], \n",
    "            'z_threshold': [4.0], \n",
    "            'T': ['84'], \n",
    "            'z': ['5.55'], \n",
    "            'p': ['1.41e-08'], \n",
    "            'prediction': ['True']\n",
    "            }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>第三个tap 生成图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正常版\n",
    "def plot(A,B,C):\n",
    "    a = A.split(' ')# a 是gamma的list\n",
    "    b = B.split(' ')# b 是 delta的list\n",
    "    c = C.split(' ')# c是 z-xx的list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不是开天眼的测试版\n",
    "def generate_plot(a,b,c):\n",
    "    x = np.linspace(0, 10, 100)\n",
    "    y = np.sin(x)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Sine Wave')\n",
    "    plt.grid(True)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>总函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'I', 'know', \"it's\", 'fiction', 'but', 'it', 'still', 'gets', 'to', \"me\\nWe're\", 'not', 'talking', 'western', 'heroes', 'so', 'I', \"don't\", 'know', 'what', \"you're\", 'talking', 'about.', '', '', '', 'And', 'action', 'movies', 'are', 'like', '90%', 'human', 'stories,', 'for', 'most', 'people', 'they', \"don't\", 'care.', '', \"That's\", 'why', 'when', 'I', 'saw', '\"Guardians', 'of', 'the', 'Galaxy', 'and', 'Thor\"', 'I', 're-watched', 'the', 'film', 'soundtrack', 'while', 'relaxing,', 'because', 'at', 'that', 'point', 'it', 'made', 'more', 'overall', 'sense', 'to', 'me', 'than', 'the', 'actual', 'movie', 'they', 'were', 'watching.\\nI', 'somehow', 'missed', 'thatggggg', 'one', 'night,', 'guess', 'I', 'should', 'give', 'it', 'another', 'go.', 'And', 'hey', 'I', 'like', 'superheroes', 'and', 'would', 'like', 'to', 'own', 'a', 'home', 'deagle', 'but', 'maybe', 'save', 'up', 'for', 'a', 'duracell?', 'idk\\nA', 'blow', 'job', 'and', 'some', 'kidneys', 'from', 'Natalie', 'Portman', 'should', 'do', 'the', 'trick.']\n",
      "\n",
      "I\n",
      "know\n",
      "it's\n",
      "fiction\n",
      "but\n",
      "it\n",
      "still\n",
      "gets\n",
      "to\n",
      "me\n",
      "We're\n",
      "not\n",
      "talking\n",
      "western\n",
      "heroes\n",
      "so\n",
      "I\n",
      "don't\n",
      "know\n",
      "what\n",
      "you're\n",
      "talking\n",
      "about.\n",
      "\n",
      "\n",
      "\n",
      "And\n",
      "action\n",
      "movies\n",
      "are\n",
      "like\n",
      "90%\n",
      "human\n",
      "stories,\n",
      "for\n",
      "most\n",
      "people\n",
      "they\n",
      "don't\n",
      "care.\n",
      "\n",
      "That's\n",
      "why\n",
      "when\n",
      "I\n",
      "saw\n",
      "\"Guardians\n",
      "of\n",
      "the\n",
      "Galaxy\n",
      "and\n",
      "Thor\"\n",
      "I\n",
      "re-watched\n",
      "the\n",
      "film\n",
      "soundtrack\n",
      "while\n",
      "relaxing,\n",
      "because\n",
      "at\n",
      "that\n",
      "point\n",
      "it\n",
      "made\n",
      "more\n",
      "overall\n",
      "sense\n",
      "to\n",
      "me\n",
      "than\n",
      "the\n",
      "actual\n",
      "movie\n",
      "they\n",
      "were\n",
      "watching.\n",
      "I\n",
      "somehow\n",
      "missed\n",
      "thatggggg\n",
      "one\n",
      "night,\n",
      "guess\n",
      "I\n",
      "should\n",
      "give\n",
      "it\n",
      "another\n",
      "go.\n",
      "And\n",
      "hey\n",
      "I\n",
      "like\n",
      "superheroes\n",
      "and\n",
      "would\n",
      "like\n",
      "to\n",
      "own\n",
      "a\n",
      "home\n",
      "deagle\n",
      "but\n",
      "maybe\n",
      "save\n",
      "up\n",
      "for\n",
      "a\n",
      "duracell?\n",
      "idk\n",
      "A\n",
      "blow\n",
      "job\n",
      "and\n",
      "some\n",
      "kidneys\n",
      "from\n",
      "Natalie\n",
      "Portman\n",
      "should\n",
      "do\n",
      "the\n",
      "trick.\n",
      "['\\nYou', 'have', 'to', 'remember', 'that', 'those', 'are', 'naturally', 'occurring', 'forces.\\nI', 'think', 'it', 'is', 'because', 'indusiadeons', 'must', 'be', 'powerfull,', 'especially', 'with', 'that', 'powerfull', 'cast', 'and', 'hel', 'mines', '-', 'ground', 'effects', 'is', 'a', 'stupid', 'concept', 'at', 'that', 'point\\nI', 'think', 'there', 'is', 'some', 'unhealthy', 'mindset', 'floating', 'about', 'among', 'indiens', 'who', 'think', 'that', 'action', 'movies', 'have', 'to', 'have', 'some', 'huge', 'clout', 'to', 'be', 'action', \"filled.\\n\\nit's\", 'about', 'people', 'who', 'you', 'want', 'to', 'make', 'for', 'some', 'major', 'action', 'scenes\\n\\nsandeners\\n\\nDec', '02', '2006,', '8:18', 'AM\\n\\nIndusiadeons', 'must', 'be', 'powerfull\\n\\nhttp://www.youtube.com/watch?v=3xwlv0qfPtI\\nYes', 'some', '(genuinely', 'powerful)', 'people', 'can', 'be', 'used', 'but', 'it', 'really', '(genuinely)', 'takes', 'nothing', 'to', 'have', 'a', 'guy', 'kick', 'some', 'guy', 'in', 'the', 'balls', 'because', '(of', 'said', 'guy)', 'getting', 'kicked', 'in', 'the', 'balls', 'is', 'painful', 'for', 'most', 'guys', 'to', 'begin', 'with....\\n\\nThose', 'moments', 'back', 'when']\n",
      "\n",
      "You\n",
      "have\n",
      "to\n",
      "remember\n",
      "that\n",
      "those\n",
      "are\n",
      "naturally\n",
      "occurring\n",
      "forces.\n",
      "I\n",
      "think\n",
      "it\n",
      "is\n",
      "because\n",
      "indusiadeons\n",
      "must\n",
      "be\n",
      "powerfull,\n",
      "especially\n",
      "with\n",
      "that\n",
      "powerfull\n",
      "cast\n",
      "and\n",
      "hel\n",
      "mines\n",
      "-\n",
      "ground\n",
      "effects\n",
      "is\n",
      "a\n",
      "stupid\n",
      "concept\n",
      "at\n",
      "that\n",
      "point\n",
      "I\n",
      "think\n",
      "there\n",
      "is\n",
      "some\n",
      "unhealthy\n",
      "mindset\n",
      "floating\n",
      "about\n",
      "among\n",
      "indiens\n",
      "who\n",
      "think\n",
      "that\n",
      "action\n",
      "movies\n",
      "have\n",
      "to\n",
      "have\n",
      "some\n",
      "huge\n",
      "clout\n",
      "to\n",
      "be\n",
      "action\n",
      "filled.\n",
      "\n",
      "it's\n",
      "about\n",
      "people\n",
      "who\n",
      "you\n",
      "want\n",
      "to\n",
      "make\n",
      "for\n",
      "some\n",
      "major\n",
      "action\n",
      "scenes\n",
      "\n",
      "sandeners\n",
      "\n",
      "Dec\n",
      "02\n",
      "2006,\n",
      "8:18\n",
      "AM\n",
      "\n",
      "Indusiadeons\n",
      "must\n",
      "be\n",
      "powerfull\n",
      "\n",
      "http://www.youtube.com/watch?v=3xwlv0qfPtI\n",
      "Yes\n",
      "some\n",
      "(genuinely\n",
      "powerful)\n",
      "people\n",
      "can\n",
      "be\n",
      "used\n",
      "but\n",
      "it\n",
      "really\n",
      "(genuinely)\n",
      "takes\n",
      "nothing\n",
      "to\n",
      "have\n",
      "a\n",
      "guy\n",
      "kick\n",
      "some\n",
      "guy\n",
      "in\n",
      "the\n",
      "balls\n",
      "because\n",
      "(of\n",
      "said\n",
      "guy)\n",
      "getting\n",
      "kicked\n",
      "in\n",
      "the\n",
      "balls\n",
      "is\n",
      "painful\n",
      "for\n",
      "most\n",
      "guys\n",
      "to\n",
      "begin\n",
      "with....\n",
      "\n",
      "Those\n",
      "moments\n",
      "back\n",
      "when\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\miniconda\\lib\\site-packages\\gradio\\queueing.py\", line 522, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"d:\\miniconda\\lib\\site-packages\\gradio\\route_utils.py\", line 260, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"d:\\miniconda\\lib\\site-packages\\gradio\\blocks.py\", line 1741, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"d:\\miniconda\\lib\\site-packages\\gradio\\blocks.py\", line 1296, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"d:\\miniconda\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"d:\\miniconda\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"d:\\miniconda\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"d:\\miniconda\\lib\\site-packages\\gradio\\utils.py\", line 751, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Charon\\AppData\\Local\\Temp\\ipykernel_16120\\3755942.py\", line 2, in random_choose\n",
      "    return utils.load_prompts()\n",
      "  File \"d:\\DDA4210\\DDA4210-PROJECT\\utils.py\", line 142, in load_prompts\n",
      "    input_text = prompts_data[sample_idx]['title']\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    # with gr.Tab(\"Raw material\"): # 新建一个 Tab\n",
    "        # prompt= gr.Textbox(lines=3,\n",
    "        #                    value=input_text, \n",
    "        #                    label=\"Prompt\")\n",
    "        # b = gr.Button(\"Generate\")\n",
    "        # o = gr.Textbox(lines=3,\n",
    "        #                 # value=original_answer, \n",
    "        #                 label=\"Original answer\")\n",
    "    # gr.Markdown(\"Prompt:\"+ input_text) \n",
    "    # gr.Markdown(\"Original_answer:\"+ original_answer)\n",
    "    with gr.Tab(\"Watermark Generation\"): # 新建一个 Tab\n",
    "        text_input = gr.Textbox(lines=5, placeholder=\"Text questions Here...\", label=\"My Prompting\")\n",
    "        Random_question_button = gr.Button(\"Random question\")\n",
    "        # Random_question = gr.Textbox(lines=3, label=\"Original answer\")\n",
    "        # input_prompt = gr.Textbox(lines=3, label=\"input_prompt\")\n",
    "        # radio = gr.Radio([\"simple\", \"Attack\"], label='Model Choice')\n",
    "\n",
    "        Generate_text_button = gr.Button(\"Generate\")\n",
    "        with gr.Row():\n",
    "            wmtext_output_1 = gr.HighlightedText(\n",
    "                            label=\"Generate without WM\",\n",
    "                            combine_adjacent=False,\n",
    "                            show_legend=True,\n",
    "                            color_map={\"+\": \"green\"})\n",
    "            wmtext_output_2 = gr.HighlightedText(\n",
    "                            label=\"Generate with WM\",\n",
    "                            combine_adjacent=False,\n",
    "                            show_legend=True,\n",
    "                            color_map={\"+\": \"green\"})\n",
    "        # wmtextboxes_row = gr.Column([wmtext_output_1, wmtext_output_2])\n",
    "        Attack_text_button = gr.Button(\"Attack\")\n",
    "        with gr.Row():\n",
    "            text_attack_1 = gr.HighlightedText(\n",
    "                            label=\"Parapharising attack\",\n",
    "                            combine_adjacent=False,\n",
    "                            show_legend=True,\n",
    "                            color_map={\"+\": \"green\"})\n",
    "            text_attack_2 = gr.HighlightedText(\n",
    "                            label=\"Substitution attack\",\n",
    "                            combine_adjacent=False,\n",
    "                            show_legend=True,\n",
    "                            color_map={\"+\": \"green\"})\n",
    "        # attackboxes_row = gr.Column([text_attack_1, text_attack_2])\n",
    "        # Evaluate_button = gr.Button(\"Evaluate\")\n",
    "        # Evaluation_output = gr.DataFrame(label= 'Evaluation Table',interactive=True,wrap=True)\n",
    "        \n",
    "    # with gr.Tab(\"Sensitivity Analysis\"): # 新建一个 Tab\n",
    "    #     parameter = [gr.Textbox(lines=1,placeholder=\"Text gamma Here...\", label=\"gamma\"),\n",
    "    #                  gr.Textbox(lines=1,placeholder=\"Text delta Here...\", label=\"delta\"),\n",
    "    #                  gr.Textbox(lines=1,placeholder=\"Text z threshold Here...\", label=\"z threshold\")]\n",
    "    #     image_button = gr.Button('visualization')\n",
    "    #     image_output= gr.Plot()\n",
    "    # with gr.Accordion(\"Open for More!\"): # 可折叠的组件\n",
    "    #     gr.Markdown(\"Look at me...\")\n",
    "\n",
    "    # b.click(initial, inputs=prompt, outputs=o) # 按钮绑定相应的槽函数\n",
    "    Random_question_button.click(random_choose, outputs=text_input)\n",
    "    Generate_text_button.click(WM, inputs=text_input, outputs=[wmtext_output_1, wmtext_output_2]) # 按钮绑定相应的槽函数\n",
    "    Attack_text_button.click(attack, outputs=[text_attack_1, text_attack_2]) # 按钮绑定相应的槽函数\n",
    "    # Evaluate_button.click(table, inputs=text_input, outputs=Evaluation_output) # 按钮绑定相应的槽函数\n",
    "    # image_button.click(plot, inputs=parameter, outputs=image_output) # 按钮绑定相应的槽函数\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
